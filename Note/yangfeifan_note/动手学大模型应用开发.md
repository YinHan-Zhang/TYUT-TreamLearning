

# 动手学大模型应用开发

## 一、大模型简介

### 1.概述

Q：什么是大模型（LLM）？

A：是指一种可以自动学习大量自然语言数据，进而生成、理解并处理人类语言的模型。这种模型可以用于自然语言处理、对话系统、机器翻译等领域，能够生成类似于人类的语言表达，从而在解决语言相关问题方面发挥重要作用。

大模型的发展历程可以总结为**神经网络模型** -->**Transformer**-->**LLM** ，随着模型参数量的上升以后，大模型具备了强大的理解能力，这一现象被称为**涌现**。

大模型使得 **通用人工智能（AGI）**成为可能，并且在自然语言处理和视觉领域也有了很大的突破。目前国内外大模型还在快速的发展迭代，多模态、长久记忆等功能都在不断的完善，我们正处于大模型时代。

### 2.大模型的能力和特点

大模型的能力主要分为三点：

* **支持对话作为统一入口的能力**。最典型的就是基于对话聊天的ChatGPT。
* **基座模型**（foundation model）。通过大模型预训练，快速开发AI应用，例如各种助手
* **涌现能力**。区分大语言模型（LLM）与以前的预训练语言模型（PLM）最显著的特征之一是它们的涌现能力。

大模型的特点主要有：

* 巨大规模参数
* 上下文感知
* 多语言
* 多模态
* 预训练和微调

### 3.常见的大模型

国内常见的大模型有**文心一言**、**讯飞星火认知大模型**、**GLM 系列模型**、**通义千问**等等。而国外的大模型有能力强大的**GPT4**、**PaLM 系列模型**、**LLaMA 系列模型**。平时我们使用的较多的开源模型主要就是ChatGLM和LLaMA，闭源模型GPT4以其强大的理解和生成能力目前还是居于榜首，国产化大模型替代还是需要有很长一段路要走。

### 4.LangChain

**LangChain 框架**是一个开源工具，充分利用了大型语言模型的强大能力，以便开发各种下游应用。它的目标是为各种大型语言模型应用提供通用接口，从而简化应用程序的开发流程。

目前国内有很多基于LangChain开发的大模型应用，是大模型开发较为主流的技术栈，Datawhale的教程也会教我们如何使用LangChain框架开发属于自己的大模型应用。

LangChain的核心组件有：

- **模型输入/输出（Model I/O）**：与语言模型交互的接口
- **数据连接（Data connection）**：与特定应用程序的数据进行交互的接口
- **链（Chains）**：将组件组合实现端到端应用。
- **记忆（Memory）**：用于链的多次运行之间持久化应用程序状态；
- **代理（Agents）**：扩展模型的推理能力。用于复杂的应用的调用序列；
- **回调（Callbacks）**：扩展模型的推理能力。用于复杂的应用的调用序列；

## 二、调用大模型API

### 1.概述

Datawhale的开源教程中给我们讲解了主流大模型（如ChatGPT、百度文心、讯飞星火、ChatGLM）的api调用和封装方法。

这里我学习使用文心一言和ChatGLM的api调用。

### 2.前置知识

#### Prompt

Prompt即提示词，可以简单理解为我们输入给大模型的指令，我们每一次访问大模型的输入为一个 Prompt，而大模型给我们的返回结果则被称为 Completion。优质的Prompt会使得大模型可以更好的理解我们的需求，提高大模型的使用效果。

#### Temprature

Temprature 参数可以来控制 LLM 生成结果的随机性与创造性。 Temprature 一般取值在 0~1 之间，当取值较低接近0时，预测的随机性会较低，产生更保守、可预测的文本。当取值较高接近1时，预测的随机性会较高，所有词被选择的可能性更大，会产生更有创意、多样化的文本。实际应用中我们应该根据需要设置不同的Temprature。

#### System Prompt 

System Prompt 是随着 ChatGPT API 开放并逐步得到大量使用的一个新兴概念，事实上，它并不在大模型本身训练中得到体现，而是大模型服务方为提升用户体验所设置的一种策略。例如：

```python
{
    "system prompt":"你是一个幽默风趣的个人知识库助手，可以根据给定的知识库内容回答用户的提问，注意，你的回答风格应是幽默风趣的",
    "user prompt":"我今天有什么事务？"
}
```

### 3.调用文心一言API



### 4.调用GLM API









