[作者小站](https://www.adit.io/index.html)
使用二分查找时，最多需要检查$log_2n$个元素，此时列表必须有序

运行时间：
线性时间:将所有的可能性都进行呈现
对数时间:二分查找的时间，或者说所有可能的操作取对数后操作数量需要的时间

大O表示法:以操作数为单位，且表示的是最糟的情形

常用的五中大O运行时间:
O(logn)
O(n)
O(n*logn)
O($n^2$)
O(n!)

算法的速度并非指时间，而是操作数的增速

谈论算法的速度时，我们说的是随着输入的增加，其运行时间将以怎样的速度增加

数组意味着存储的元素紧挨的放在一起，如果你需要增加一个元素，那么只能重新申请一块地址，虽然可以预留位置，但这可能造成内存的浪费，并且超过数组长度后还需要进行转移
 
链表则解决了这个问题，相当于说：我们分开坐

但是如果要随机读取链表中的一个元素，那么效率就会很低，但如果随机读取数组中的元素，那么效率就会很高，直接根据索引来即可

插入元素时，链表只需修改在这个元素之前的元素存储的下个元素的地址
而数组则需将插入位置之后的元素都向后移动，而且如果数组没有足够的空间的话，需要重新分配空间

删除元素时，也是链表更为方便，只需要删除前一个元素指向的地址即可

|      | 数组 | 链表 |
| ---- | ---- | ---- |
| 读取 | O(1) | O(n) |
| 插入 | O(n) | O(1) |
| 删除 | O(n) | O(1) |

### 递归
循环有时可能性能更好，但是递归更容易理解

编写递归时，必须告诉他什么时候停止递归。所以每个递归函数都应该有两个条件:<mark>基线条件(base case)</mark>和<mark>递归条件(recusive case)</mark>。
递归条件指的是调用自己，基线条件指的是不调用自己，从而避免无限循环


### 栈
栈只有两种操作:入栈与出栈

当执行一个函数时，计算机会将函数调用涉及的所有变量的值存储到内存中，在该函数中调用另一个函数时，当前函数暂停并处于未完成状态，执行完内层函数后，回到之前的函数从离开的地方继续执行

这个栈被称为调用栈

![](../../blog_picture/stack1.png)
![](../../blog_picture/stack2.png)
![](../../blog_picture/stack3.png)
![](../../blog_picture/stack4.png)

在递归函数中，外层函数执行到return后，就进入该函数调用的里层函数，然后重复，直到进入最里层函数，最里层函数返回确定值，在逐一返回外层函数
<mark>另外，在这个过程中，里层与外层函数的相同名称变量并不相同</mark>

使用循环方法时，相当于将所有的盒子摆出来查找
![](../..\blog_picture\stack5.png)

使用递归时，则相当于将这些盒子嵌套起来，在盒子中找东西就是入栈的过程

![](../..\blog_picture\stack6.png)

![](../..\blog_picture\stack7.png)

虽然栈很方便。但是存储详尽的信息可能占用大量的内存，如果栈很高，则说明计算机存储了大量函数调用的信息:
改善方法:
重新编写代码，使用循环
使用尾递归

## 快速排序
探索<mark>分而治之(divide and conquer,D & C)</mark>-一种著名的递归式问题解决方法，分而治之就是先将问题规模减小，然后处理。

快速排序是一种D&C算法

使用D&C解决问题的过程包括两个步骤：
- 找出基线条件，这种条件必须尽可能简单
- 不断将问题分解(缩小问题规模)，直到符合基线条件

归纳证明:
归纳证明是一种证明算法行之有效的方式，它分为:基线条件与归纳条件。

归纳条件就是说从k可以推到k+1，基线条件就是说k=1时有效。

### 算法复杂度中的常量
两个大O表示法相同复杂度的算法，常量会使得它们的速度不同，例如：快速排序和合并查找但是如果大O表示法不同，那么常量的影响就可以忽略不计了。

<mark>算法所需的固定时间量，称为常量</mark>

### 平均情况与最佳情况
![](../..\blog_picture\最糟情况.png)
最糟情况是每次将第一个元素作为基准值，由于数组并没有被分为两半，会进行n次

平均情况/最佳情况
![](../..\blog_picture\平均情况.png)
但是如果每次将数组分为两半，就不需要那么多递归调用了，只需要进行$logn$次

两种方法的<mark>调用栈的高度</mark>分别为$O(n)$与$O(logn)$

每层完成的操作时间为$O(n)$<mark>注意是$O(n)$而不是n</mark>
![](../..\blog_picture\every.png)

所以，对快速排序来说，最佳情况是$O(n)*O(logn)=O(nlogn)$
最糟情况是$O(n)*O(n)=O(n^2)$

## 散列表
需要满足一些要求:
- 输入相同时，输出也需要相同
- 应该将不同的输入映射到不同的数字

散列函数使我们不用查找，一步到位，之所以能做到这样，是因为：
- 散列函数总是将同样的输入映射到相同的索引

- 散列函数将不同的输入映射到不同的索引

- 散列函数只返回有效索引

数组与链表都被直接映射到内存，但是散列表更复杂，它使用散列函数来确定元素的存储位置,包含了额外的逻辑

散列表又称为散列映射、映射、字典和关联数组。

任意优秀的语言都提供了散列表实现，在python中，这就是字典dict

### 将散列表用于查找
Python中创建一个散列表:
```python
new_dict=dict()
new_dict={}
```
在访问网站时，链接都会被转换为IP地址访问，散列表可以提供这种功能，这种功能称为DNS解析(Domain Name System)域名解析

缓存的原理：网站将数据记住，而不需要再进行重新获取
![](../..\blog_picture\webcache.png)
这是一个URL与页面数据的散列表
![](../..\blog_picture\缓存.png)


小结一下：
散列表适用于
- 模拟映射关系
- 防止重复
- 缓存/记住数据，以防服务器再通过处理来生成这些数据

在散列表中，当两个输入对应同一个输出时，就意味着发生了冲突(collision)。

最简单的解决办法是:
如果两个键映射到了同一位置，那么就在这个位置存储一个链表

我们在选择散列函数时需要注意:
- 好的散列函数可以将键均匀地映射到散列表的不同位置
- 好的散列函数不会令链表变得很长

虽然散列表在平均情况下，所有的操作都是常量时间O(1)，但是在最糟情况下，其查找、插入、删除时间都是O(n)

因此，避开最糟情况很重要，为此，需要避开冲突
- 较低的填装因子
- 良好的散列函数

填装因子:
$\frac{散列表中的元素数}{位置总数}$
当填装因子大于0.7意味着商品数量超过了数组的位置数，需要在散列表中添加位置，称为调整长度(resizing)

填装因子越小，发生冲突的可能性越小

散列函数:
良好的散列函数可以让数组中的值均匀分布

广度优先搜索(breadth-first search,BFS)

最短路径问题(shortest-path problem)，解决最短路径问题的算法被称为广度优先搜索。

图是什么
图由节点与边组成

两节点间若有一条边相连，则两节点互为邻居。

广度优先搜索先搜索一度关系，再搜索二度关系

### 队列
队列只支持两种操作:入队与出队
队列是一种先进先出的数据结构，而栈是一种后进先出的数据结构。

python中创建一个双端队列
```python
from collection import deque 
search_queue=deque()
```

键值对的添加顺序没有影响，因为散列表无序

有向图(directed graph)带有箭头
无向图(undirected graph)不带有箭头

检查完一个人后就应该将它标记，否则可能会陷入无限循环，而且会多做很多无用功

广度优先搜索的运行时间:
因为要将每个人加入到队列中，所以为O(人数),又因为要检查每个人，沿着图的边进行，所以为O(边数),总时间为O(顶点数+边数)

## 迪杰斯特拉算法(Dijkstra's Algorithm)
在使用广度优先搜索时，找到的是从起点开始，经过边数最少的路径，但是当每条边被分配了权重后，再使用广度优先搜索时就不好用了。

而迪杰斯特拉算法可以找到总权重最小的路径。

步骤:
- 1.找到最近的节点
- 2.对于该最近结点的邻居，检查与当前前往它们的距离相比是否有更近的距离，如果有就更新
- 3.重复这个过程，直到遍历完整个图
- 4.计算最终路径

迪杰斯特拉算法其实就是一种每次都选最优解的算法，贪心
### 术语
权重:图中的每条边都有关联数字，这些数字就是权重

加权图:带权重的图就称为加权图

非加权图:不带权重的图

计算非加权图中的最短路径，可以使用广度优先搜索

计算加权图中的最短路径，可以使用迪杰斯特拉算法

环:从一个点出发，如果有一条路径能够走回这个点，那么这就是一个环

其实无向图就意味着有环

迪杰斯特拉算法只适用于有向无环图(directed acyclic graph,DAG)

### 负权边
当两个结点之间的权值为负数时，就不能使用迪杰斯特拉算法了，因为权值为负时，会导致:
一个已经被标记了最短路径的结点，在另一条路径中出现了更短的到达这个结点的路径，但是这条更短的路径已经无法更新了。

要解决带负权边的图的最短路径问题，可以使用贝尔曼-福德算法(Bellman-Ford Algorithm)

### 实现
python中创建一个无穷大的数的表示：
```python
infinity=float("inf")
```

## 贪婪算法
贪婪算法的优点:
简单易行，即每步都选择局部最优解，最终得到的就是全局最优解

<mark>当然，贪婪算法并非在任何情况下都有效</mark>

在很多情况下，完美是优秀的敌人，有时候，只需要找到一个能够大致解决问题的算法，此时贪婪算法恰好可以派上用场。

贪婪算法虽然并不一定能得到最优解，但是可以得到近似解，评价近似解优劣的标准:
- 速度有多快
- 得到的近似解与最优解的接近程度


### NP完全问题
如果能够识别一个问题时NP完全问题，那么我们现在还没有找到最佳的解决方法,最佳的做法是使用近似算法。<mark>但是现在没办法判断问题是不是NP完全问题</mark>。

以下是一些经验:
- 元素较少时算法的运行速度非常快，但随着元素数量的增加，速度会变得非常慢。
- 涉及“所有组合”的问题通常是NP完全问题。
- 不能将问题分成小问题，必须考虑各种可能的情况。这可能是NP完全问题。
- 如果问题涉及序列（如旅行商问题中的城市序列）且难以解决，它可能就是NP完全问题。
- 如果问题涉及集合（如广播台集合）且难以解决，它可能就是NP完全问题。
- 如果问题可转换为集合覆盖问题或旅行商问题，那它肯定是NP完全问题。

## 动态规划
将大问题分解为很多个小问题

无法解决只拿商品的一部分的问题。

动态规划也无法解决子问题之间存在相互依赖关系的情况。

计算最终解时只涉及两个背包，但是在这两个背包里可能还有子背包。

动态规划的启示:
- 动态规划可以帮助你在给定约束条件下找到最优解
- 在问题可以被分解为<mark>彼此独立</mark>且离散的问题时，就可以使用动态规划来解决
- 每种动态规划解决方案都涉及网格
- 单元格中的值通常就是你要优化的值
- 每个单元格都是一个子问题，因此应该考虑如何将问题分解为子问题，有助于找到网格的坐标轴

对于不同的问题，网格中的答案的位置也不相同，对于背包问题，答案总是存在于最后一个单元格中，但对于寻找最长公子串问题，答案则为整个网格中的最大数字。

动态规划的实际应用:
- 根据最长公共序列来确定DNA链的相似性，进而判断两种动物或疾病有多相似
- git diff也是用动态规划实现的
- 编辑距离(levenshtein distancec)指出了两个字符串的相似程度。

## 最近邻算法(KNN,k-nearest neighbours)
将离这个物体最近的邻居的某些特征赋予这个物体或加以处理赋予这个物体

### 特征抽取
在比较两个物体是否相似时，其实是对它们的特征进行判断，将特征数值化，然后可以使用毕达哥拉斯公式来进行距离的度量。

毕达哥拉斯公式:就是勾股定理，它可以将斜边的距离表示为两点横纵坐标差值的平方和开根。

在KNN中，如果两个用户的特征有因为个体原因导致的差异时，可以使用归一化来降低这种个体差异。

如果两个邻居的地位不同，可以为一个邻居的影响力赋予更大的权重。

### 余弦相似度
计算两个用户的距离时，除了距离公式，还可以使用余弦相似度。它比较的不是两个点的距离，而是两个向量的角度，<mark>这可以有效地避免两点特征值大小偏好带来的差异</mark>

### 特征的选择
选取与要推荐的事物密切相关的特征
选取不偏好任何一方的特征(比如不能只选取动作片还要有喜剧片)

当然，没有放之四海皆准的法则，必须考虑到尽可能多的因素。

### OCR(光学字符识别-optical character recognize)
提取数字的特征来利用KNN识别这些特征，但是提取的特征要比水果复杂很多。

### 创建垃圾邮件过滤器
使用朴素贝叶斯分类器(Naive Bayes classifier)

### 二叉查找树(binary search tree)
二叉查找树中查找节点时，平均运行时间为O(log n),而且它的插入与删除操作要快很多。

它也存在缺点：比如不能进行随机访问。

而且当二叉树并不平衡时，性能也会不好，因为当不平衡时，做得就和二分查找法有一些不同了。

### 反向索引
创建一个散列表，令其中的键为单词，值为包含单词的页面。

这样当搜索单词时，就会出现包含它的页面，这成为反向索引(inverted index)。

### 傅里叶变换
可以分析信号中的组成成分。

### 并行算法
并行算法设计起来很难，要确保它们能够正确地工作并实现期望的速度提升也很难。

并行算法的速度提升是非线性的，原因有两个:
- 并行管理开销：
    如果采用数据并行，那么不同核之间结果的合并仍需要花费时间
- 负载均衡
    任务的分配并非按任务个数分配，不同任务的难度不同，所以均匀地分配任务也是一个难题

### Mapreduce
一种特殊的并行算法是分布式算法，可以让算法在多台计算机上运行，可以通过开源工具Apache Hadoop来实现。

分布式算法适用于在短时间内完成海量工作，其中的mapreduce基于两个简单的理念:
map(映射)与reduce(归并)

映射就是对一些对象同时执行相同的操作映射为处理后的对象

归并就是将多项归并为一项

### 布隆过滤器
当我们想判断一个网页是否在某个名单里(比如说黑名单中),可以使用散列表，这样得到的结果绝对可靠，但是，这也会造成大量的内存消耗。

为此，我们可以使用布隆过滤器，这是一种概率型的数据结构，它的答案很可能是正确的，它可能错报但不会漏报。

适用于并不要求答案绝对正确的情况下。

### Hyperloglog
类似于布隆过滤器

### SHA算法
另一种散列函数是一种安全散列算法(secure hash algorithm)，给定一个字符串，SHA返回一个散列值。

可以使用SHA来判断两个文件是否相同。

通过字符串可以很轻易地知道散列值，但是通过散列值却极难知道字符串。

SHA有一个重要的特征，那就是局部不敏感算法，对一个字符串即使只修改了一个字符，也会产生截然不同的散列值

但有时候，你希望这种微小的改变使散列值的改变也微小，这时就可以使用Simhash。它可以让两个相似的字符串产生相似的散列值，用来比较两个字符串的相似程度。

### Diffie-Hellman密钥交换
如果只是使用数字-单词的对应关系作为加密，首先需要达成算法一致，要达成一致就必须见面，因为电子邮件很容易被劫持，而即便见面也仍有可能泄露。而这种对应关系也可以被破译。

Diffie-Hellman算法解决了两个问题:
- 双方无需知道加密算法
- 要破解加密的消息难如登天

用公钥加密的信息只有用私钥才能解开。

### 线性规划
如果你对最优化感兴趣就研究线性规划吧。

